{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6e245b-a16e-4d89-803c-1ce496d367f8",
   "metadata": {},
   "source": [
    "### Day 4: Advanced Python Libraries and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474e67a-8422-459f-a145-17fc1df41d3f",
   "metadata": {},
   "source": [
    "#### Keras Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d486dd-9000-4c18-9102-63c9d39a1b78",
   "metadata": {},
   "source": [
    "##### Keras Model Building APIs \n",
    "+ are essentially different approaches to constructing neural networks, each with its own use cases and benefits\n",
    "+ The **Sequential API** is the simplest and most straightforward - it's perfect for basic neural networks where data flows straight from input to output through each layer.\n",
    "+ The **Functional API** offers more flexibility - can create models with multiple inputs or outputs, share layers between different parts of the model, or create models with branching paths\n",
    "+ **Model Subclassing** is the most flexible but also most complex approach - can define custom layers, create dynamic model architectures, and implement complex training logic; for research or when need complete control over the model's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2d484-e1c4-4dcf-9292-0af708ae591d",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bc8b8-6430-433e-a074-2edb8987a99e",
   "metadata": {},
   "source": [
    "#### Layer Types and Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e1e26-e426-42c0-9b12-c15adec99dec",
   "metadata": {},
   "source": [
    "+ `Dense (Fully Connected) Layers` are the most basic - every neuron connects to every neuron in the previous layer. They're great for learning patterns across your entire input. Think of them as the \"generalist\" layers that can process any type of flattened input data.\n",
    "\n",
    "+ `Convolutional Layers (Conv2D, Conv3D)` are specialized for spatial data like images. They look at small regions of the input at a time, making them excellent at detecting patterns like edges, textures, and shapes.\n",
    "\n",
    "+ `Recurrent Layers (LSTM, GRU)` are designed for sequential data like text or time series. They maintain a form of \"memory\" of previous inputs, making them ideal for understanding context in sequences. Long Short-Term Memory (LSTM) layers are particularly good at learning long-term dependencies, while GRU (Gated Recurrent Unit) layers are simpler and often faster to train.\n",
    "\n",
    "+ `Pooling Layers (MaxPooling, AveragePooling)` reduce the spatial dimensions of your data. They help make your model more efficient and robust by summarizing regions of features.\n",
    "\n",
    "+ `Dropout Layers` are used for preventing overfitting. They randomly \"turn off\" a portion of neurons during training, forcing the network to be more robust and not rely too heavily on any single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86107422-073d-4c2e-a28b-8dea0a49a2c6",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e43c4-fb28-4ffe-8b2a-f793cc9f2c5b",
   "metadata": {},
   "source": [
    "#### Model Compliation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ee65e-6cbc-4c81-820e-8095a2ec9a50",
   "metadata": {},
   "source": [
    "+ **compilation of a model** involves defining the optimizer, the loss function, and the metrics.\n",
    "+ 1. `Optimizer`: determines how the model updates its weights during training; includes Adam (adapts learning rates automatically); Stochastic Gradient Descent, RMSProp (good for RNN), Adagrad (adapts learning rates for each parameter)\n",
    "  \n",
    "+ 2. `Loss Function`: measures how well the model is performing; includes binary cross-entropy; categorical cross-entropy (classification); mean squarer eddor for regression\n",
    " \n",
    "+ 3. `Metrics`: additional measures to monitor during training (like accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7692c-7503-4fbb-85ed-b16e1bb3bb7f",
   "metadata": {},
   "source": [
    "**Training** involves:\n",
    "+ 1. Batch Size: How many samples the model processes before updating weights\n",
    "+ 2. Epochs: Complete passes through the entire dataset\n",
    "+ 3. Validation: Using a separate dataset to check for overfitting\n",
    "+ 4. Learning Rate: How large the weight updates are (usually handled by optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152c1e9-4d37-4754-957f-de8d4fc2586f",
   "metadata": {},
   "source": [
    "The **actual training** process involves:\n",
    "+ 1. Forward Pass: Model makes predictions on a batch of data\n",
    "+ 3. Loss Calculation: Comparing predictions to actual values\n",
    "+ 3. Backward Pass: Computing gradients\n",
    "+ 4. Weight Updates: Adjusting model parameters to reduce loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c513d4d-5729-4509-a836-8ba229f62d3e",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbe41a-24a7-42e8-aedc-c2baa64bdb34",
   "metadata": {},
   "source": [
    "#### Callbacks and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1be63-4796-4e9d-a6f8-2e8afba5a62a",
   "metadata": {},
   "source": [
    "+ Callbacks and Monitoring in Keras - these are essential tools for tracking and controlling the training process. For **callbacks**, they can:\n",
    "    + Save Model checkpoints - Automatically saves your model at specific points\n",
    "    + Early Stopping - Prevents overfitting by stopping when model stops improving\n",
    "    + Learning Rate Scheduling - Adjusts learning rate during training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab41f0-a245-4fc5-acfc-ea3d8d07093e",
   "metadata": {},
   "source": [
    "**Monitoring** includes:\n",
    "+ Training Loss: Shows how well model is learning\n",
    "+ Validation Metrics: Indicates generalization performance\n",
    "+ Resource Usage: CPU/GPU utilization, memory usage\n",
    "+ Gradient Values: Helps detect issues like vanishing/exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535d9a0-294e-492d-b8aa-64f94526a6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (PyTorch)",
   "language": "python",
   "name": "torch-ml-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
