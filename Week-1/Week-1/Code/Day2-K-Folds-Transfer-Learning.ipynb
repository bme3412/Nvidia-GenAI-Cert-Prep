{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8736f98-3984-4010-8b20-40a57b387392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/brendan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3aac3b-a9b4-4b93-9aa3-33aded9f8f2e",
   "metadata": {},
   "source": [
    "## Generate Synthetic Financial Data\n",
    "We'll create a synthetic dataset simulating earnings call transcripts and financial metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fca5b67d-10f2-47b2-af9d-e3c09b8fd500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of synthetic data:\n",
      "        date     company      sector  speaker  \\\n",
      "0 2023-01-01    RetailCo      Retail      CFO   \n",
      "1 2023-01-02    EnergyCo  Technology      CFO   \n",
      "2 2023-01-03  HealthCare      Retail      CFO   \n",
      "3 2023-01-04    EnergyCo     Finance  Analyst   \n",
      "4 2023-01-05    EnergyCo  Technology  Analyst   \n",
      "\n",
      "                                          transcript      revenue  \\\n",
      "0  Our fourth quarter showed strong growth with r...  1073.381883   \n",
      "1  Despite market challenges, we achieved first g...  1041.899373   \n",
      "2  Despite market challenges, we achieved third g...   824.887642   \n",
      "3  Our first quarter showed strong growth with re...   953.030333   \n",
      "4  The third initiative has yielded positive resu...   802.554158   \n",
      "\n",
      "   growth_rate  sentiment_score  \n",
      "0    12.358102         0.899667  \n",
      "1     9.138580         0.624102  \n",
      "2     8.876016         0.539781  \n",
      "3     7.543969         0.438745  \n",
      "4     8.124285         0.577486  \n"
     ]
    }
   ],
   "source": [
    "# Generate dates\n",
    "np.random.seed(42)\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=x) for x in range(100)]\n",
    "\n",
    "# Generate synthetic data\n",
    "companies = ['TechCorp', 'FinanceInc', 'HealthCare', 'RetailCo', 'EnergyCo']\n",
    "sectors = ['Technology', 'Finance', 'Healthcare', 'Retail', 'Energy']\n",
    "speakers = ['CEO', 'CFO', 'Analyst']\n",
    "\n",
    "# Sample earnings call snippets\n",
    "call_templates = [\n",
    "    \"Our {} quarter showed strong growth with revenue up {}%. We're investing in {}.\",\n",
    "    \"Despite market challenges, we achieved {} growth in our {} segment.\",\n",
    "    \"The {} initiative has yielded positive results, with margins expanding {}%.\"\n",
    "]\n",
    "\n",
    "def generate_call_text():\n",
    "    template = np.random.choice(call_templates)\n",
    "    return template.format(\n",
    "        np.random.choice(['first', 'second', 'third', 'fourth']),\n",
    "        np.random.randint(5, 25),\n",
    "        np.random.choice(['AI', 'cloud', 'mobile', 'sustainability'])\n",
    "    )\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'date': dates,\n",
    "    'company': [np.random.choice(companies) for _ in range(100)],\n",
    "    'sector': [np.random.choice(sectors) for _ in range(100)],\n",
    "    'speaker': [np.random.choice(speakers) for _ in range(100)],\n",
    "    'transcript': [generate_call_text() for _ in range(100)],\n",
    "    'revenue': np.random.normal(1000, 200, 100),\n",
    "    'growth_rate': np.random.normal(10, 3, 100),\n",
    "    'sentiment_score': np.random.uniform(0, 1, 100)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['revenue'] = np.abs(df['revenue'])  # Ensure positive revenues\n",
    "\n",
    "print(\"Sample of synthetic data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541decd7-2d88-49e2-be14-5a6a684874fa",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Implement various feature engineering techniques for:\n",
    "- Numerical features\n",
    "- Categorical features\n",
    "- Time-based features\n",
    "- Text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05e7ffaf-776a-4a04-a714-2925dcc34746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed features shape: (100, 19)\n",
      "Text features shape: (100, 48)\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.tfidf = TfidfVectorizer(max_features=100)\n",
    "        \n",
    "    def engineer_numerical_features(self, df):\n",
    "        # Copy to avoid modifying original\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Scale numerical features\n",
    "        numerical_cols = ['revenue', 'growth_rate']\n",
    "        df_processed[numerical_cols] = self.scaler.fit_transform(df_processed[numerical_cols])\n",
    "        \n",
    "        # Create revenue bins\n",
    "        df_processed['revenue_bin'] = pd.qcut(df_processed['revenue'], \n",
    "                                            q=3, \n",
    "                                            labels=['low', 'medium', 'high'])\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def engineer_categorical_features(self, df):\n",
    "        # One-hot encoding for sector\n",
    "        sector_dummies = pd.get_dummies(df['sector'], prefix='sector')\n",
    "        \n",
    "        # Label encoding for speaker\n",
    "        df['speaker_encoded'] = self.label_encoder.fit_transform(df['speaker'])\n",
    "        \n",
    "        return pd.concat([df, sector_dummies], axis=1)\n",
    "    \n",
    "    def engineer_time_features(self, df):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        \n",
    "        # Add rolling means\n",
    "        df['rolling_growth'] = df.groupby('company')['growth_rate'].rolling(window=3).mean().reset_index(0, drop=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def engineer_text_features(self, texts):\n",
    "        return self.tfidf.fit_transform(texts)\n",
    "\n",
    "# Apply feature engineering\n",
    "fe = FeatureEngineer()\n",
    "df_processed = df.pipe(fe.engineer_numerical_features)\\\n",
    "                 .pipe(fe.engineer_categorical_features)\\\n",
    "                 .pipe(fe.engineer_time_features)\n",
    "\n",
    "text_features = fe.engineer_text_features(df['transcript'])\n",
    "\n",
    "print(\"\\nProcessed features shape:\", df_processed.shape)\n",
    "print(\"Text features shape:\", text_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f2fb0-a3b3-4cc7-8134-8bfdd51cf4aa",
   "metadata": {},
   "source": [
    "## Simple Neural Network for Financial Prediction\n",
    "Create a basic neural network for **predicting sentiment** based on engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41772dc0-eed3-4f63-af62-511311300afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature tensor shape: torch.Size([100, 56])\n",
      "Target tensor shape: torch.Size([100])\n",
      "\n",
      "Model structure:\n",
      "FinancialNN(\n",
      "  (layer1): Linear(in_features=56, out_features=64, bias=True)\n",
      "  (layer2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (layer3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class FinancialNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Prepare data for PyTorch\n",
    "def prepare_data(df_processed, text_features):\n",
    "    # Combine numerical and one-hot encoded features\n",
    "    numerical_cols = ['revenue', 'growth_rate', 'speaker_encoded']\n",
    "    categorical_cols = [col for col in df_processed.columns if col.startswith('sector_')]\n",
    "    \n",
    "    # Convert to float32 explicitly\n",
    "    numerical_features = df_processed[numerical_cols].values.astype(np.float32)\n",
    "    categorical_features = df_processed[categorical_cols].values.astype(np.float32)\n",
    "    text_features_array = text_features.toarray().astype(np.float32)\n",
    "    \n",
    "    # Combine all features\n",
    "    features = np.hstack([\n",
    "        numerical_features,\n",
    "        categorical_features,\n",
    "        text_features_array\n",
    "    ])\n",
    "    \n",
    "    targets = df_processed['sentiment_score'].values.astype(np.float32)\n",
    "    \n",
    "    return torch.FloatTensor(features), torch.FloatTensor(targets)\n",
    "\n",
    "# Prepare data\n",
    "X, y = prepare_data(df_processed, text_features)\n",
    "print(\"Feature tensor shape:\", X.shape)\n",
    "print(\"Target tensor shape:\", y.shape)\n",
    "\n",
    "# Initialize model\n",
    "model = FinancialNN(input_dim=X.shape[1])\n",
    "print(\"\\nModel structure:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310a7bc-25ca-419e-8230-cb8b9316cb7c",
   "metadata": {},
   "source": [
    "## Cross Validation Implementation\n",
    "Implement both k-fold and time series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fe8891d-dc88-4b3d-a308-a540642ec99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross Validation:\n",
      "Fold 1 validation loss: 0.0799\n",
      "Fold 2 validation loss: 0.0801\n",
      "Fold 3 validation loss: 0.0603\n",
      "Fold 4 validation loss: 0.0582\n",
      "Fold 5 validation loss: 0.0829\n",
      "\n",
      "Mean validation loss: 0.0723 (±0.0107)\n",
      "\n",
      "Time Series Cross Validation:\n",
      "Time split 1 validation loss: 0.0536\n",
      "Time split 2 validation loss: 0.0592\n",
      "Time split 3 validation loss: 0.1079\n",
      "Time split 4 validation loss: 0.0775\n",
      "Time split 5 validation loss: 0.0822\n",
      "\n",
      "Mean validation loss: 0.0761 (±0.0192)\n"
     ]
    }
   ],
   "source": [
    "class CrossValidator:\n",
    "    def __init__(self, model, X, y):\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        self.time_split = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "    def train_fold(self, train_idx, val_idx):\n",
    "        X_train, X_val = self.X[train_idx], self.X[val_idx]\n",
    "        y_train, y_val = self.y[train_idx], self.y[val_idx]\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        \n",
    "        # Simple training loop\n",
    "        for epoch in range(10):  # 10 epochs per fold\n",
    "            # Train\n",
    "            self.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.model(X_train)\n",
    "            loss = criterion(y_pred, y_train.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validate\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(X_val)\n",
    "            val_loss = criterion(y_pred, y_val.unsqueeze(1))\n",
    "            \n",
    "        return val_loss.item()\n",
    "    \n",
    "    def k_fold_cv(self):\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kfold.split(self.X)):\n",
    "            fold_score = self.train_fold(train_idx, val_idx)\n",
    "            fold_scores.append(fold_score)\n",
    "            print(f\"Fold {fold + 1} validation loss: {fold_score:.4f}\")\n",
    "        \n",
    "        return np.mean(fold_scores), np.std(fold_scores)\n",
    "    \n",
    "    def time_series_cv(self):\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.time_split.split(self.X)):\n",
    "            fold_score = self.train_fold(train_idx, val_idx)\n",
    "            fold_scores.append(fold_score)\n",
    "            print(f\"Time split {fold + 1} validation loss: {fold_score:.4f}\")\n",
    "        \n",
    "        return np.mean(fold_scores), np.std(fold_scores)\n",
    "\n",
    "# Run cross validation\n",
    "cv = CrossValidator(model, X, y)\n",
    "print(\"K-Fold Cross Validation:\")\n",
    "mean_score, std_score = cv.k_fold_cv()\n",
    "print(f\"\\nMean validation loss: {mean_score:.4f} (±{std_score:.4f})\")\n",
    "\n",
    "print(\"\\nTime Series Cross Validation:\")\n",
    "mean_score, std_score = cv.time_series_cv()\n",
    "print(f\"\\nMean validation loss: {mean_score:.4f} (±{std_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153d0dd-38c9-4a6f-9947-2ccef5e23501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (PyTorch)",
   "language": "python",
   "name": "torch-ml-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
