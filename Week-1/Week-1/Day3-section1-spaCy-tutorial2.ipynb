{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e0eab7-3ea4-4ba7-a7c5-70777dde5935",
   "metadata": {},
   "source": [
    "#### NLP with spaCY part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7e832-25f9-4825-a027-50f81ceba57d",
   "metadata": {},
   "source": [
    "#### Chapter 2: Large-scale data analysis with spaCy\n",
    "+ extract specific information from large volumes of text using spaCy's data structures, and combine statistical and rule-based approaches for text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef856e0-7908-4c30-8755-be368811efd0",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3653ae1b-302d-4ddf-8738-4c96f3577db2",
   "metadata": {},
   "source": [
    "#### Data Structures\n",
    "+ `Vocab`: stores data shared across multiple documents; To save memory, spaCy encodes all strings to hash values\n",
    "+ It's a lookup table that works in both directions. You can look up a string and get its hash, and look up a hash to get its string value.\n",
    "+ To get the hash for a string, we can look it up in `nlp.vocab.strings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0a6fd5-c251-4437-bc67-1d22ad25d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3197928453018144401\n",
      "string value: coffee\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "doc = nlp(\"I love coffee\")\n",
    "print(\"hash value:\", nlp.vocab.strings[\"coffee\"])\n",
    "print(\"string value:\", nlp.vocab.strings[3197928453018144401])\n",
    "\n",
    "nlp.vocab.strings.add(\"coffee\")\n",
    "coffee_hash = nlp.vocab.strings[\"coffee\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5ea6b-edd6-4869-9a36-90d4964802e4",
   "metadata": {},
   "source": [
    "**Lexemes** are context-independent entries in the vocabulary.\n",
    "+ You can get a lexeme by looking up a string or a hash ID in the vocab.\n",
    "+ They hold context-independent information about a word, like the text, or whether the word consists of alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3ca662-8093-4b85-8687-022b4d031bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee 3197928453018144401 True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love coffee\")\n",
    "lexeme = nlp.vocab[\"coffee\"]\n",
    "\n",
    "# Print the lexical attributes {text, hash, and is it alphabetic value}\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52bc76-f0ca-49c9-8552-614a451e5f45",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd2d93-a292-4d05-bac1-55d17d8f79df",
   "metadata": {},
   "source": [
    "#### Strings to Hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2547245-5466-4309-99ad-78124b12c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5439657043933447811\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Look up the string “cat” in nlp.vocab.strings to get the hash.\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"I have a cat\")\n",
    "\n",
    "# Look up the hash for the word \"cat\"\n",
    "cat_hash = nlp.vocab.strings['cat']\n",
    "print(cat_hash)\n",
    "\n",
    "# Look up the cat_hash to get the string\n",
    "cat_string = nlp.vocab.strings[cat_hash]\n",
    "print(cat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5252c37b-75a6-4c71-ba10-44906e8889bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "PERSON\n"
     ]
    }
   ],
   "source": [
    "# Look up the string label “PERSON” in nlp.vocab.strings to get the hash.\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"David Bowie is a PERSON\")\n",
    "\n",
    "# Look up the hash for the string label \"PERSON\"\n",
    "person_hash = nlp.vocab.strings['PERSON']\n",
    "print(person_hash)\n",
    "\n",
    "# Look up the person_hash to get the string\n",
    "person_string = nlp.vocab.strings[person_hash]\n",
    "print(person_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab002ab8-a930-4906-8e1d-cb4f9f612732",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598299c2-9da8-4b1e-9dda-c24f90f8f7b6",
   "metadata": {},
   "source": [
    "#### Data Structures 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46ca61-c6e4-4ce9-94f9-ec5e0013ecb1",
   "metadata": {},
   "source": [
    "##### The Doc Object\n",
    "+ it's created automatically when you process a text with the nlp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66089e12-3a32-472d-bcde-782cb732cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75752dfa-cd0a-4465-ac93-44db911b6860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello world!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a930d5d-51d0-4e4d-b054-a87fbf0c808c",
   "metadata": {},
   "source": [
    "##### The Span Object 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936523e-8336-4540-b3c7-450bd537b1fa",
   "metadata": {},
   "source": [
    "+ To create a Span manually, we can also import the class from spacy.tokens. We can then instantiate it with the doc and the span's start and end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e03fb0-7ef7-437e-9a46-b36bab77eead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello world!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Doc and Span classes\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# Create a span manually\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "# Create a span with a label\n",
    "span_with_label = Span(doc, 0, 2, label=\"GREETING\")\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = [span_with_label]\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7be975-366e-4f26-80aa-0ec0c5504f9f",
   "metadata": {},
   "source": [
    "##### Create a Doc from the words and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fcb3ef-cda4-4ae2-ab6f-889b1a0d05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is cool!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"spaCy is cool!\"\n",
    "words = [\"spaCy\", \"is\", \"cool\", \"!\"]\n",
    "spaces = [True, True, False, False]\n",
    "\n",
    "# create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdecc8c-3834-4425-8e60-84284fedff92",
   "metadata": {},
   "source": [
    "##### Create a Doc from the words and spaces. Don’t forget to pass in the vocab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea22da5-a8e0-4299-87e2-c8fbff82aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go, get started! \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "words = [\"Go\", \",\", \"get\", \"started\", \"!\"]\n",
    "spaces = [False, True, True, False, True]\n",
    "\n",
    "# create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb57ffe-c10d-41ce-abec-1b29eef540d4",
   "metadata": {},
   "source": [
    "##### Complete the words and spaces to match the desired text and create a doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8283af8-6617-44a9-b18c-df22867f8b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, really?!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"Oh, really?!\"\n",
    "words = [\"Oh\", ',', 'really', '?', \"!\"]\n",
    "spaces = [False, True, False,False, False]\n",
    "\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ea30b-9c62-46ed-9919-98a859dcfeb9",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c67910-7022-4e73-a6de-1a3179876f80",
   "metadata": {},
   "source": [
    "#### Docs, Spans, and entities from scratch\n",
    "+ create the Doc and Span objects manually, and update the named entities – just like spaCy does behind the scenes.\n",
    "+ A shared nlp object has already been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d585ee3-c8fb-4285-8e6e-dd342ecb77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like David Bowie\n",
      "David Bowie PERSON\n",
      "[('David Bowie', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Import the Doc and Span classes\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "words = [\"I\", \"like\", \"David\", \"Bowie\"]\n",
    "spaces = [True, True, True, False]\n",
    "\n",
    "# Create a doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)\n",
    "\n",
    "# Create a span for \"David Bowie\" from the doc and assign it the label \"PERSON\"\n",
    "span = Span(doc, 2, 4, label='PERSON')\n",
    "print(span.text, span.label_)\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = [span]\n",
    "\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc9814-3fc9-4bf7-b7e6-22c96c2c73d5",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5d75c-849a-45c3-a2b5-a3eb546b07e0",
   "metadata": {},
   "source": [
    "#### Word vectors and semantic similarity\n",
    "+ spaCy can compare two objects and predict how similar they are – for example, documents, spans or single tokens\n",
    "+ We can then create two doc objects and use the first doc's **similarity method** to compare it to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b953d6-830f-4b09-b0e6-4e25c604c47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8382381200790405\n"
     ]
    }
   ],
   "source": [
    "# Load a larger pipeline with vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Compare two documents\n",
    "doc1 = nlp(\"I like fast food\")\n",
    "doc2 = nlp(\"I like pizza\")\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc531673-e880-4223-a0f6-42e653df9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "# Compare two tokens\n",
    "doc = nlp(\"I like pizza and pasta\")\n",
    "token1 = doc[2]\n",
    "token2 = doc[4]\n",
    "print(token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2dfe9-c9ef-49c5-a110-b7c8e089004e",
   "metadata": {},
   "source": [
    "+ You can also use the similarity methods to compare different types of objects; For example, a document and a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de738366-8894-4a6d-a737-9ea4255975f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2274084836244583\n"
     ]
    }
   ],
   "source": [
    "# Compare a document with a token\n",
    "doc = nlp(\"I like pizza\")\n",
    "token = nlp(\"soap\")[0]\n",
    "\n",
    "print(doc.similarity(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d061d917-4471-4319-9bde-7d5a9b626429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5528544783592224\n"
     ]
    }
   ],
   "source": [
    "# Compare a span with a document\n",
    "span = nlp(\"I like pizza and pasta\")[2:5]\n",
    "doc = nlp(\"McDonalds sells burgers\")\n",
    "\n",
    "print(span.similarity(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59456897-c29e-4b13-bcd7-41599db16fed",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704dd3c1-0f36-409d-89b5-7d551a806746",
   "metadata": {},
   "source": [
    "#### How does spaCy predict similarity?\n",
    "+ Similarity is determined using word vectors, multi-dimensional representations of meanings of words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74eb639-24bf-4299-9f17-9693708d93c2",
   "metadata": {},
   "source": [
    "#### Word vectors in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba8f04b7-23a7-477e-92a8-266db5fd0d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6334     0.18981   -0.53544   -0.52658   -0.30001    0.30559\n",
      " -0.49303    0.14636    0.012273   0.96802    0.0040354  0.25234\n",
      " -0.29864   -0.014646  -0.24905   -0.67125   -0.053366   0.59426\n",
      " -0.068034   0.10315    0.66759    0.024617  -0.37548    0.52557\n",
      "  0.054449  -0.36748   -0.28013    0.090898  -0.025687  -0.5947\n",
      " -0.24269    0.28603    0.686      0.29737    0.30422    0.69032\n",
      "  0.042784   0.023701  -0.57165    0.70581   -0.20813   -0.03204\n",
      " -0.12494   -0.42933    0.31271    0.30352    0.09421   -0.15493\n",
      "  0.071356   0.15022   -0.41792    0.066394  -0.034546  -0.45772\n",
      "  0.57177   -0.82755   -0.27885    0.71801   -0.12425    0.18551\n",
      "  0.41342   -0.53997    0.55864   -0.015805  -0.1074    -0.29981\n",
      " -0.17271    0.27066    0.043996   0.60107   -0.353      0.6831\n",
      "  0.20703    0.12068    0.24852   -0.15605    0.25812    0.007004\n",
      " -0.10741   -0.097053   0.085628   0.096307   0.20857   -0.23338\n",
      " -0.077905  -0.030906   1.0494     0.55368   -0.10703    0.052234\n",
      "  0.43407   -0.13926    0.38115    0.021104  -0.40922    0.35972\n",
      " -0.28898    0.30618    0.060807  -0.023517   0.58193   -0.3098\n",
      "  0.21013   -0.15557   -0.56913   -1.1364     0.36598   -0.032666\n",
      "  1.1926     0.12825   -0.090486  -0.47965   -0.61164   -0.16484\n",
      " -0.41134    0.19925    0.059183  -0.20842    0.45223    0.27697\n",
      " -0.20745    0.025404  -0.28874    0.040478  -0.22275   -0.43323\n",
      "  0.76957   -0.054327  -0.35213   -0.30842   -0.48791   -0.35564\n",
      "  0.19813   -0.094767  -0.50918    0.18763   -0.087555   0.37709\n",
      " -0.1322    -0.096913  -1.9102     0.55813    0.27391   -0.077744\n",
      " -0.43933   -0.10367   -0.24408    0.41869    0.11659    0.27454\n",
      "  0.81021   -0.11006    0.43131    0.29095   -0.49548   -0.31958\n",
      " -0.072506   0.020286   0.2179     0.22032   -0.29212    0.75639\n",
      "  0.13598    0.019736  -0.83104    0.22836   -0.28669   -1.0529\n",
      "  0.052771   0.41266    0.50149    0.5323     0.51573   -0.31806\n",
      " -0.4619     0.21739   -0.43584   -0.41382    0.042237  -0.57179\n",
      "  0.067623  -0.27854    0.090044   0.20633    0.024678  -0.57703\n",
      " -0.020183  -0.53147   -0.37548   -0.12795   -0.093662  -0.0061183\n",
      "  0.20221   -0.62296   -0.29746    0.26935    0.59009   -0.50382\n",
      " -0.69757    0.20157   -0.33592   -0.45766    0.14061    0.22982\n",
      "  0.044046   0.26386    0.02942    0.34095    1.1496    -0.15555\n",
      " -0.064071   0.30139    0.024211  -0.63515   -0.73347   -0.10346\n",
      " -0.22637   -0.056392  -0.16735   -0.097331  -0.19206   -0.18866\n",
      "  0.15116   -0.038048   0.70205    0.11586   -0.14813    0.0095166\n",
      " -0.33804   -0.10158   -0.23829   -0.22759    0.092504  -0.29839\n",
      " -0.39721    0.26092    0.34594   -0.47396   -0.25725   -0.19257\n",
      " -0.53071    0.1692    -0.47252   -0.17333   -0.40505    0.046446\n",
      " -0.04473    0.33555   -0.5693     0.31591   -0.21167   -0.31298\n",
      " -0.45923   -0.083091   0.086822   0.01264    0.43779    0.12651\n",
      "  0.30156    0.022061   0.26549   -0.29455   -0.14838    0.033692\n",
      " -0.37346   -0.075343  -0.56498   -0.24207   -0.69351   -0.20277\n",
      " -0.0081185  0.030971   0.53615   -0.16613   -0.84087    0.74661\n",
      "  0.029132   0.46936   -0.49755    0.40954   -0.022558   0.21497\n",
      " -0.049528  -0.039799   0.46165    0.26456    0.32985   -0.04219\n",
      " -0.099599  -0.17312   -0.476     -0.019048  -0.41888   -0.2685\n",
      " -0.65281    0.068773  -0.23881   -1.1784     0.25504    0.61171  ]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"I have a banana\")\n",
    "# Access the vector via the token.vector attribute\n",
    "print(doc[3].vector)\n",
    "\n",
    "## The result is a 300-dimensional vector of the word \"banana\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f4f6d-ef42-40c5-817d-744095f4107e",
   "metadata": {},
   "source": [
    "#### Inspecting word vectors\n",
    "+ Load the medium \"en_core_web_md\" pipeline with word vectors.; Print the vector for \"bananas\" using the token.vector attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc4844a2-5085-458e-ac85-e7c3c99f3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6334     0.18981   -0.53544   -0.52658   -0.30001    0.30559\n",
      " -0.49303    0.14636    0.012273   0.96802    0.0040354  0.25234\n",
      " -0.29864   -0.014646  -0.24905   -0.67125   -0.053366   0.59426\n",
      " -0.068034   0.10315    0.66759    0.024617  -0.37548    0.52557\n",
      "  0.054449  -0.36748   -0.28013    0.090898  -0.025687  -0.5947\n",
      " -0.24269    0.28603    0.686      0.29737    0.30422    0.69032\n",
      "  0.042784   0.023701  -0.57165    0.70581   -0.20813   -0.03204\n",
      " -0.12494   -0.42933    0.31271    0.30352    0.09421   -0.15493\n",
      "  0.071356   0.15022   -0.41792    0.066394  -0.034546  -0.45772\n",
      "  0.57177   -0.82755   -0.27885    0.71801   -0.12425    0.18551\n",
      "  0.41342   -0.53997    0.55864   -0.015805  -0.1074    -0.29981\n",
      " -0.17271    0.27066    0.043996   0.60107   -0.353      0.6831\n",
      "  0.20703    0.12068    0.24852   -0.15605    0.25812    0.007004\n",
      " -0.10741   -0.097053   0.085628   0.096307   0.20857   -0.23338\n",
      " -0.077905  -0.030906   1.0494     0.55368   -0.10703    0.052234\n",
      "  0.43407   -0.13926    0.38115    0.021104  -0.40922    0.35972\n",
      " -0.28898    0.30618    0.060807  -0.023517   0.58193   -0.3098\n",
      "  0.21013   -0.15557   -0.56913   -1.1364     0.36598   -0.032666\n",
      "  1.1926     0.12825   -0.090486  -0.47965   -0.61164   -0.16484\n",
      " -0.41134    0.19925    0.059183  -0.20842    0.45223    0.27697\n",
      " -0.20745    0.025404  -0.28874    0.040478  -0.22275   -0.43323\n",
      "  0.76957   -0.054327  -0.35213   -0.30842   -0.48791   -0.35564\n",
      "  0.19813   -0.094767  -0.50918    0.18763   -0.087555   0.37709\n",
      " -0.1322    -0.096913  -1.9102     0.55813    0.27391   -0.077744\n",
      " -0.43933   -0.10367   -0.24408    0.41869    0.11659    0.27454\n",
      "  0.81021   -0.11006    0.43131    0.29095   -0.49548   -0.31958\n",
      " -0.072506   0.020286   0.2179     0.22032   -0.29212    0.75639\n",
      "  0.13598    0.019736  -0.83104    0.22836   -0.28669   -1.0529\n",
      "  0.052771   0.41266    0.50149    0.5323     0.51573   -0.31806\n",
      " -0.4619     0.21739   -0.43584   -0.41382    0.042237  -0.57179\n",
      "  0.067623  -0.27854    0.090044   0.20633    0.024678  -0.57703\n",
      " -0.020183  -0.53147   -0.37548   -0.12795   -0.093662  -0.0061183\n",
      "  0.20221   -0.62296   -0.29746    0.26935    0.59009   -0.50382\n",
      " -0.69757    0.20157   -0.33592   -0.45766    0.14061    0.22982\n",
      "  0.044046   0.26386    0.02942    0.34095    1.1496    -0.15555\n",
      " -0.064071   0.30139    0.024211  -0.63515   -0.73347   -0.10346\n",
      " -0.22637   -0.056392  -0.16735   -0.097331  -0.19206   -0.18866\n",
      "  0.15116   -0.038048   0.70205    0.11586   -0.14813    0.0095166\n",
      " -0.33804   -0.10158   -0.23829   -0.22759    0.092504  -0.29839\n",
      " -0.39721    0.26092    0.34594   -0.47396   -0.25725   -0.19257\n",
      " -0.53071    0.1692    -0.47252   -0.17333   -0.40505    0.046446\n",
      " -0.04473    0.33555   -0.5693     0.31591   -0.21167   -0.31298\n",
      " -0.45923   -0.083091   0.086822   0.01264    0.43779    0.12651\n",
      "  0.30156    0.022061   0.26549   -0.29455   -0.14838    0.033692\n",
      " -0.37346   -0.075343  -0.56498   -0.24207   -0.69351   -0.20277\n",
      " -0.0081185  0.030971   0.53615   -0.16613   -0.84087    0.74661\n",
      "  0.029132   0.46936   -0.49755    0.40954   -0.022558   0.21497\n",
      " -0.049528  -0.039799   0.46165    0.26456    0.32985   -0.04219\n",
      " -0.099599  -0.17312   -0.476     -0.019048  -0.41888   -0.2685\n",
      " -0.65281    0.068773  -0.23881   -1.1784     0.25504    0.61171  ]\n"
     ]
    }
   ],
   "source": [
    "# Load the en_core_web_md pipeline\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"Two bananas in pyjamas\")\n",
    "\n",
    "# Get the vector for the token \"bananas\"\n",
    "bananas_vector = doc[1].vector\n",
    "print(bananas_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1477b-2b21-4454-b35f-57965bfe70a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (PyTorch)",
   "language": "python",
   "name": "torch-ml-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
